---
name: clawgate
description: Smart LLM routing proxy stats and control. Use when the user asks about API costs, model routing, token usage, cache hit rates, provider health, or wants to test how a prompt would be routed. Commands â€” /clawgate stats, /clawgate route, /clawgate health, /clawgate daily.
metadata: {"openclaw":{"requires":{"bins":["curl"]},"emoji":"ðŸšª","homepage":"https://github.com/langenetwork/clawgate"}}
---

# ClawGate â€“ LLM Routing Proxy Skill

ClawGate is a local routing proxy that sits between OpenClaw and your LLM providers (DeepSeek, Gemini, OpenRouter). It routes each request to the cheapest model that can handle it using a 3-layer classification engine.

## Available Commands

### /clawgate stats
Show full routing statistics: total requests, cost, tokens, cache hit rate, per-provider breakdown.

```bash
curl -s http://127.0.0.1:8090/api/stats | python3 -m json.tool
```

Format the output as a clean summary table showing:
- Total requests, total cost (USD), avg latency
- Cache hit rate (higher = more savings from DeepSeek/Gemini prefix caching)
- Per-provider: requests, tokens, cost, cache%, failures
- Top routing rules by usage

### /clawgate health
Check provider health status.

```bash
curl -s http://127.0.0.1:8090/health | python3 -m json.tool
```

Show each provider's health status, consecutive failures, and average latency. Flag any unhealthy providers.

### /clawgate daily
Show daily cost breakdown with projected monthly cost.

```bash
curl -s http://127.0.0.1:8090/api/stats | python3 -c "
import sys,json
d=json.load(sys.stdin)
daily=d.get('daily',[])
for day in daily:
    print(f\"{day['day']}  reqs={day['requests']:4d}  cost=\${day['cost_usd']:.4f}  tokens={day['tokens']}\")
if daily:
    avg=sum(x['cost_usd'] for x in daily)/len(daily)
    print(f'---')
    print(f'Avg/day: \${avg:.4f}  Projected/month: \${avg*30:.2f}')
"
```

### /clawgate route <message>
Dry-run: show which provider a message would be routed to without actually sending it. Useful for testing routing rules.

```bash
curl -s http://127.0.0.1:8090/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "auto",
    "messages": [{"role": "user", "content": "USER_MESSAGE_HERE"}],
    "max_tokens": 1
  }' 2>&1 | head -1
```

Note: This sends a real request with max_tokens=1 to see the routing decision in the X-ClawGate-Provider response header. For zero-cost testing, check the server logs instead:

```bash
# Watch routing decisions in real-time
journalctl -u clawgate -f --output=cat | grep "Route:"
```

### /clawgate recent
Show the last 10 requests with provider, layer, rule, tokens, cost, and status.

```bash
curl -s 'http://127.0.0.1:8090/api/recent?limit=10' | python3 -c "
import sys,json,time
d=json.load(sys.stdin)
for r in d.get('requests',[]):
    ago=time.time()-r['timestamp']
    t=f'{ago/60:.0f}m' if ago<3600 else f'{ago/3600:.1f}h'
    tok=r.get('prompt_tok',0)+r.get('compl_tok',0)
    print(f\"{t:>6s} ago  {r['provider']:20s} {r['layer']:10s} {r['rule_name']:20s} {tok:>6d}tok  \${r.get('cost_usd',0):.4f}  {'âœ“' if r.get('success') else 'âœ—'}\")
"
```

## Dashboard

A web dashboard is available at http://127.0.0.1:8090/dashboard â€” open it in a browser for a live view with auto-refresh.

## How Routing Works

ClawGate uses 3 layers (evaluated in order, first match wins):

1. **Static rules**: Pattern matching on model name, system prompt keywords, headers (heartbeats, explicit model requests, subagent detection)
2. **Heuristic scoring**: Keyword-weighted classification of user messages (NOT system prompt) into reasoning/code/simple/agent categories
3. **LLM classifier** (optional): Cheapest model classifies the task when heuristics are uncertain

Key insight: Only user messages are scored, never the system prompt. OpenClaw's system prompt is large and keyword-rich â€” scoring it would route everything to the expensive reasoning tier.

## Prompt Caching

DeepSeek and Gemini automatically cache repeated prefixes server-side. ClawGate tracks cache hit/miss tokens in metrics. To maximize cache hits:
- Keep system prompts stable (identical prefix between requests)
- Push variable content to the end of messages
- Use few-shot examples consistently

Cache pricing: DeepSeek charges ~10x less for cache hits ($0.014/M vs $0.14/M for cache miss).
